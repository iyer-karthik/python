#### Multi Armed Bandit testing for Thompson Sampling. 

The goal here is to test out Thompson Sampling for Multi-armed bandit using different learning
rates and see how fast the algorithm coverges to the true winner. 

Disclaimer: Code heavily borrows (almost verbatim copy) from Cam Davidson
Pilon's book "Bayesian Methods for Hackers" (Chapter 6)
